{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-20T19:35:26.835416Z",
     "end_time": "2023-05-20T19:35:27.812736Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "         tweet_id   author_id  inbound                      created_at   \n0               1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017  \\\n1               2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n2               3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n3               4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n4               5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n...           ...         ...      ...                             ...   \n2811769   2987947  sprintcare    False  Wed Nov 22 08:43:51 +0000 2017   \n2811770   2987948      823869     True  Wed Nov 22 08:35:16 +0000 2017   \n2811771   2812240      121673     True  Thu Nov 23 04:13:07 +0000 2017   \n2811772   2987949      AldiUK    False  Wed Nov 22 08:31:24 +0000 2017   \n2811773   2987950      823870     True  Tue Nov 21 22:01:04 +0000 2017   \n\n                                                      text response_tweet_id   \n0        @115712 I understand. I would like to assist y...                 2  \\\n1            @sprintcare and how do you propose we do that               NaN   \n2        @sprintcare I have sent several private messag...                 1   \n3        @115712 Please send us a Private Message so th...                 3   \n4                                       @sprintcare I did.                 4   \n...                                                    ...               ...   \n2811769  @823869 Hey, we'd be happy to look into this f...               NaN   \n2811770  @115714 wtf!? I‚Äôve been having really shitty s...           2987947   \n2811771  @143549 @sprintcare You have to go to https://...               NaN   \n2811772  @823870 Sounds delicious, Sarah! üòã https://t.c...               NaN   \n2811773  @AldiUK  warm sloe gin mince pies with ice cre...   2987951,2987949   \n\n         in_response_to_tweet_id  \n0                            3.0  \n1                            1.0  \n2                            4.0  \n3                            5.0  \n4                            6.0  \n...                          ...  \n2811769                2987948.0  \n2811770                      NaN  \n2811771                2812239.0  \n2811772                2987950.0  \n2811773                      NaN  \n\n[2811774 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>author_id</th>\n      <th>inbound</th>\n      <th>created_at</th>\n      <th>text</th>\n      <th>response_tweet_id</th>\n      <th>in_response_to_tweet_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n      <td>@115712 I understand. I would like to assist y...</td>\n      <td>2</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n      <td>@sprintcare I have sent several private messag...</td>\n      <td>1</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n      <td>@115712 Please send us a Private Message so th...</td>\n      <td>3</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n      <td>@sprintcare I did.</td>\n      <td>4</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2811769</th>\n      <td>2987947</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Wed Nov 22 08:43:51 +0000 2017</td>\n      <td>@823869 Hey, we'd be happy to look into this f...</td>\n      <td>NaN</td>\n      <td>2987948.0</td>\n    </tr>\n    <tr>\n      <th>2811770</th>\n      <td>2987948</td>\n      <td>823869</td>\n      <td>True</td>\n      <td>Wed Nov 22 08:35:16 +0000 2017</td>\n      <td>@115714 wtf!? I‚Äôve been having really shitty s...</td>\n      <td>2987947</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2811771</th>\n      <td>2812240</td>\n      <td>121673</td>\n      <td>True</td>\n      <td>Thu Nov 23 04:13:07 +0000 2017</td>\n      <td>@143549 @sprintcare You have to go to https://...</td>\n      <td>NaN</td>\n      <td>2812239.0</td>\n    </tr>\n    <tr>\n      <th>2811772</th>\n      <td>2987949</td>\n      <td>AldiUK</td>\n      <td>False</td>\n      <td>Wed Nov 22 08:31:24 +0000 2017</td>\n      <td>@823870 Sounds delicious, Sarah! üòã https://t.c...</td>\n      <td>NaN</td>\n      <td>2987950.0</td>\n    </tr>\n    <tr>\n      <th>2811773</th>\n      <td>2987950</td>\n      <td>823870</td>\n      <td>True</td>\n      <td>Tue Nov 21 22:01:04 +0000 2017</td>\n      <td>@AldiUK  warm sloe gin mince pies with ice cre...</td>\n      <td>2987951,2987949</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2811774 rows √ó 7 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/dpatel112/OneDrive - Cal State LA/Spring 2023/CS5660 Artificial Intelligence/Project/twcs/twcs.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-20T19:37:38.431584Z",
     "end_time": "2023-05-20T19:37:48.575555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method DataFrame.info of          tweet_id   author_id  inbound                      created_at   \n0               1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017  \\\n1               2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n2               3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n3               4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n4               5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n...           ...         ...      ...                             ...   \n2811769   2987947  sprintcare    False  Wed Nov 22 08:43:51 +0000 2017   \n2811770   2987948      823869     True  Wed Nov 22 08:35:16 +0000 2017   \n2811771   2812240      121673     True  Thu Nov 23 04:13:07 +0000 2017   \n2811772   2987949      AldiUK    False  Wed Nov 22 08:31:24 +0000 2017   \n2811773   2987950      823870     True  Tue Nov 21 22:01:04 +0000 2017   \n\n                                                      text response_tweet_id   \n0        @115712 I understand. I would like to assist y...                 2  \\\n1            @sprintcare and how do you propose we do that               NaN   \n2        @sprintcare I have sent several private messag...                 1   \n3        @115712 Please send us a Private Message so th...                 3   \n4                                       @sprintcare I did.                 4   \n...                                                    ...               ...   \n2811769  @823869 Hey, we'd be happy to look into this f...               NaN   \n2811770  @115714 wtf!? I‚Äôve been having really shitty s...           2987947   \n2811771  @143549 @sprintcare You have to go to https://...               NaN   \n2811772  @823870 Sounds delicious, Sarah! üòã https://t.c...               NaN   \n2811773  @AldiUK  warm sloe gin mince pies with ice cre...   2987951,2987949   \n\n         in_response_to_tweet_id  \n0                            3.0  \n1                            1.0  \n2                            4.0  \n3                            5.0  \n4                            6.0  \n...                          ...  \n2811769                2987948.0  \n2811770                      NaN  \n2811771                2812239.0  \n2811772                2987950.0  \n2811773                      NaN  \n\n[2811774 rows x 7 columns]>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-20T19:37:52.174743Z",
     "end_time": "2023-05-20T19:37:52.186916Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dpatel112\\AppData\\Local\\Temp\\ipykernel_15468\\3107920159.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tqdm_notebook().pandas()\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43443552c1bc4c8dacc1fc3fee1262d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get customer requests and company responses\n",
    "from tqdm import tqdm_notebook\n",
    "first_inbound = df[pd.isnull(df.in_response_to_tweet_id) & df.inbound]\n",
    "inbounds_and_outbounds = pd.merge(first_inbound, df, left_on='tweet_id', right_on='in_response_to_tweet_id')\n",
    "tqdm_notebook().pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-20T19:37:54.371387Z",
     "end_time": "2023-05-20T19:37:55.683779Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\dpatel112\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.6696"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Instantiate sentiment analyzer from NLTK, make helper function\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_for(text: str) -> float:\n",
    "    return sentiment_analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "sentiment_for('I love it!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-20T19:37:57.279008Z",
     "end_time": "2023-05-20T19:37:59.403556Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dpatel112\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-20T19:38:01.862217Z",
     "end_time": "2023-05-20T19:38:01.923238Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0          understand would like assist would need get pr...\n1                                         sprintcare propose\n2          sprintcare sent several private message one re...\n3          please send u private message assist click mes...\n4                                                 sprintcare\n                                 ...                        \n2811769    hey happy look please send u direct message as...\n2811770      wtf really shitty service day get shit together\n2811771    sprintcare go http co v tmhetl q ask add hulu ...\n2811772               sound delicious sarah http co uqpwyh b\n2811773    aldiuk warm sloe gin mince pie ice cream best ...\nName: cleaned_text, Length: 2811774, dtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Define stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define function for text cleaning\n",
    "def preprocess_text(text):\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    # Join the cleaned tokens back into a string\n",
    "    cleaned_text = \" \".join(cleaned_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply text preprocessing to relevant columns\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "df['cleaned_text']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-20T19:38:03.072296Z",
     "end_time": "2023-05-20T19:44:22.809773Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_id                         0\n",
      "author_id                        0\n",
      "inbound                          0\n",
      "created_at                       0\n",
      "text                             0\n",
      "response_tweet_id          1040629\n",
      "in_response_to_tweet_id     794335\n",
      "cleaned_text                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-20T19:55:48.430259Z",
     "end_time": "2023-05-20T19:55:48.950551Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   tweet_id   author_id  inbound                      created_at   \n0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017  \\\n1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n\n                                                text response_tweet_id   \n0  @115712 I understand. I would like to assist y...                 2  \\\n1      @sprintcare and how do you propose we do that               NaN   \n2  @sprintcare I have sent several private messag...                 1   \n3  @115712 Please send us a Private Message so th...                 3   \n4                                 @sprintcare I did.                 4   \n\n   in_response_to_tweet_id                                       cleaned_text  \n0                      3.0  understand would like assist would need get pr...  \n1                      1.0                                 sprintcare propose  \n2                      4.0  sprintcare sent several private message one re...  \n3                      5.0  please send u private message assist click mes...  \n4                      6.0                                         sprintcare  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>author_id</th>\n      <th>inbound</th>\n      <th>created_at</th>\n      <th>text</th>\n      <th>response_tweet_id</th>\n      <th>in_response_to_tweet_id</th>\n      <th>cleaned_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n      <td>@115712 I understand. I would like to assist y...</td>\n      <td>2</td>\n      <td>3.0</td>\n      <td>understand would like assist would need get pr...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n      <td>@sprintcare and how do you propose we do that</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>sprintcare propose</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n      <td>@sprintcare I have sent several private messag...</td>\n      <td>1</td>\n      <td>4.0</td>\n      <td>sprintcare sent several private message one re...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>sprintcare</td>\n      <td>False</td>\n      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n      <td>@115712 Please send us a Private Message so th...</td>\n      <td>3</td>\n      <td>5.0</td>\n      <td>please send u private message assist click mes...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>115712</td>\n      <td>True</td>\n      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n      <td>@sprintcare I did.</td>\n      <td>4</td>\n      <td>6.0</td>\n      <td>sprintcare</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['text', 'inbound'], inplace=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-20T19:55:50.109620Z",
     "end_time": "2023-05-20T19:55:51.333084Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Thank you for your prompt response!\n",
      "Requires Response: No\n",
      "---\n",
      "Tweet: I need help with my order.\n",
      "Requires Response: Yes\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.94      0.96    254749\n",
      "        True       0.95      0.99      0.97    307606\n",
      "\n",
      "    accuracy                           0.97    562355\n",
      "   macro avg       0.97      0.97      0.97    562355\n",
      "weighted avg       0.97      0.97      0.97    562355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Prepare the features (tweet text) and target variable (requires_response)\n",
    "X = df['text']\n",
    "y = df['inbound']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the text data and convert to numerical features\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "new_tweets = ['Thank you for your prompt response!', 'I need help with my order.']\n",
    "new_tweets_vectorized = vectorizer.transform(new_tweets)\n",
    "predictions = classifier.predict(new_tweets_vectorized)\n",
    "\n",
    "# Print the predictions\n",
    "for tweet, prediction in zip(new_tweets, predictions):\n",
    "    print(f'Tweet: {tweet}')\n",
    "    print(f'Requires Response: {\"Yes\" if prediction else \"No\"}')\n",
    "    print('---')\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-20T19:55:55.335299Z",
     "end_time": "2023-05-20T19:56:45.034757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "! @AmericanAir doesn't have bereavement prices üëÄ. Really?! My mom just called and the customer service lady was like 'nope! not here' #sad                         1\n",
      "! @Ask_Spectrum Cullman, AL completely down - any ETA??                                                                                                            1\n",
      "! I cannot do that question mark thingy that everyone with Apple can do! @AppleSupport help me out                                                                 1\n",
      "!!! Estoy frustrado !!! \\nNecesito recomendaciones URGENTE\\nTengo COMCAST y me esta dando mucho problema con el... https://t.co/IBEEazEjZc                         1\n",
      "!!! https://t.co/QLe6BqXlEy                                                                                                                                        1\n",
      "                                                                                                                                                                  ..\n",
      "ü¶ÉGuess what day it is tomorrow? Thanksgiving!! It‚Äôs that time of the year! Time for giving thanks with friends, family and loved ones!! https://t.co/YQo3vBGdZe    1\n",
      "ü¶Ñ (unicorn) cake cake cake #office #birthday @marksandspencer üíïüéÇ https://t.co/QnvoDg13xy                                                                           1\n",
      "üßê @AppleSupport how come background picture r zoomed in so much for iPhone 8? I want the whole picture as my background? Like my 5S #helpplease                    1\n",
      "üßê looks about right ü§ù https://t.co/MvjKjBFuXO                                                                                                                      1\n",
      "üßïüèΩ @delta                                                                                                                                                          1\n",
      "Length: 2782618, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_counts = df.groupby(['text']).size()\n",
    "print(sentiment_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-20T19:57:16.288623Z",
     "end_time": "2023-05-20T19:57:23.784482Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
